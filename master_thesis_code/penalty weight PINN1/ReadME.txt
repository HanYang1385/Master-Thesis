1. 文件夹“文章中实验一训练好的神经网络”中保存了实验一训练好的神经网络，
直接加载使用即可得到文章中的实验结果.

2. 在调参时注意batch size和步长，我的经验是用逐渐增大的batch size效果最好，
我用的策略是每隔几万步batch size*2，这样可以逐渐降低信噪比；步长用固定的步长就好(一般可取1e-4,1e-5,1e-6).
我的经验是batch size影响最大.此外调参时要注意观察误差的变化，根据误差变化调参.

3. 因为训练比较耗时间，所以可以用continu_train继续之前的训练过程.

4. 若权函数发生改变，需要重新训练神经网络.

5. 实际不需要训练如此长的时间，可以训练更少的步数，此处是为了结果更稳定.

Python=3.7


